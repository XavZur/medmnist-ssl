{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af1e92e8",
   "metadata": {},
   "source": [
    "# MedMNIST Week 2 — EDA, Baselines & Calibration Example\n",
    "\n",
    "This notebook is an example for **Week 2** of the `medmnist-ssl` project.\n",
    "\n",
    "It assumes you have already chosen one binary MedMNIST2D dataset (`breastmnist` or `pneumoniamnist`) and follows the same style as the Week 1 notebook:\n",
    "- Quick dataset inspection (EDA)\n",
    "- Two supervised baselines (`smallcnn`, `resnet18 --finetune head`)\n",
    "- First calibration snapshot (reliability diagram + ECE)\n",
    "- A small misclassified example gallery\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6795fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(\"PyTorch:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0821b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install medmnist torch torchvision scikit-learn matplotlib tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb01d3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import medmnist\n",
    "from medmnist import INFO\n",
    "\n",
    "# Choose ONE binary dataset for the entire project\n",
    "DATASET_KEY = 'pneumoniamnist'  # or 'breastmnist'\n",
    "\n",
    "info = INFO[DATASET_KEY]\n",
    "DataClass = getattr(medmnist, info['python_class'])\n",
    "\n",
    "train_ds_raw = DataClass(split='train', download=True)\n",
    "val_ds_raw   = DataClass(split='val',   download=True)\n",
    "test_ds_raw  = DataClass(split='test',  download=True)\n",
    "\n",
    "print(\"Cache root:\", train_ds_raw.root)\n",
    "print(\"Train shape:\", train_ds_raw.imgs.shape)\n",
    "print(\"Val shape:\",   val_ds_raw.imgs.shape)\n",
    "print(\"Test shape:\",  test_ds_raw.imgs.shape)\n",
    "print(\"Labels:\", info['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c42a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "def describe_split(name, ds):\n",
    "    labels = np.array(ds.labels).squeeze()\n",
    "    counts = Counter(labels.tolist())\n",
    "    print(f\"{name} size:\", len(labels))\n",
    "    for k in sorted(counts):\n",
    "        print(f\"  class {k}: {counts[k]}\")\n",
    "    print()\n",
    "\n",
    "describe_split(\"Train\", train_ds_raw)\n",
    "describe_split(\"Val\",   val_ds_raw)\n",
    "describe_split(\"Test\",  test_ds_raw)\n",
    "\n",
    "# Visualize a small grid of images per class (from the train split)\n",
    "n_per_class = 4\n",
    "labels = np.array(train_ds_raw.labels).squeeze()\n",
    "classes = sorted(set(labels.tolist()))\n",
    "\n",
    "rows = len(classes)\n",
    "cols = n_per_class\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(cols * 2.0, rows * 2.0))\n",
    "\n",
    "if rows == 1:\n",
    "    axes = np.expand_dims(axes, axis=0)  # make it 2D for uniform indexing\n",
    "\n",
    "for row, cls in enumerate(classes):\n",
    "    idxs = np.where(labels == cls)[0][:n_per_class]\n",
    "    for col, idx in enumerate(idxs):\n",
    "        ax = axes[row, col]\n",
    "        img = train_ds_raw.imgs[idx]\n",
    "        if img.ndim == 2:\n",
    "            ax.imshow(img, cmap='gray')\n",
    "        else:\n",
    "            ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f\"y={cls}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c6cefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as tvm\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "from medmnist import INFO\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def get_medmnist_dataset(key: str, split: str, as_rgb: bool = True, size: int = 64, download: bool = True):\n",
    "    info = INFO[key]\n",
    "    DataClass = getattr(medmnist, info['python_class'])\n",
    "    tf = [T.Resize((size, size)), T.ToTensor()]\n",
    "    if as_rgb:\n",
    "        # Repeat grayscale channel to RGB if needed\n",
    "        tf.append(T.Lambda(lambda x: x.repeat(3, 1, 1) if x.shape[0] == 1 else x))\n",
    "    transform = T.Compose(tf)\n",
    "    return DataClass(split=split, transform=transform, download=download)\n",
    "\n",
    "def get_loaders(key, batch_size: int = 128, num_workers: int = 2, label_frac: float = 1.0, seed: int = 42):\n",
    "    set_seed(seed)\n",
    "    ds_train = get_medmnist_dataset(key, 'train')\n",
    "    ds_val   = get_medmnnist_dataset(key, 'val') if False else get_medmnist_dataset(key, 'val')\n",
    "    ds_test  = get_medmnist_dataset(key, 'test')\n",
    "\n",
    "    n_classes = len(INFO[key]['label'])\n",
    "\n",
    "    # Optional: subsample labels for label-efficiency experiments (not used by default in Week 2)\n",
    "    if 0 < label_frac < 1.0:\n",
    "        labels = np.array([int(t[1]) for t in ds_train])\n",
    "        rng = np.random.RandomState(seed)\n",
    "        idxs = []\n",
    "        for c in np.unique(labels):\n",
    "            c_idxs = np.where(labels == c)[0]\n",
    "            rng.shuffle(c_idxs)\n",
    "            n_keep = max(1, int(len(c_idxs) * label_frac))\n",
    "            idxs.extend(c_idxs[:n_keep])\n",
    "        idxs = np.sort(np.array(idxs))\n",
    "        ds_train = Subset(ds_train, idxs)\n",
    "\n",
    "    train_loader = DataLoader(ds_train, batch_size=batch_size, shuffle=True,  num_workers=num_workers)\n",
    "    val_loader   = DataLoader(ds_val,   batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    test_loader  = DataLoader(ds_test,  batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    return train_loader, val_loader, test_loader, n_classes\n",
    "\n",
    "class SmallCNN(nn.Module):\n",
    "    def __init__(self, in_ch: int = 3, n_classes: int = 2):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, 32, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "        )\n",
    "        self.fc = nn.Linear(128, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.flatten(1)\n",
    "        return self.fc(x)\n",
    "\n",
    "def make_resnet18(n_classes: int = 2, in_ch: int = 3, pretrained: bool = True):\n",
    "    m = tvm.resnet18(weights=tvm.ResNet18_Weights.IMAGENET1K_V1 if pretrained else None)\n",
    "    if in_ch != 3:\n",
    "        w = m.conv1.weight\n",
    "        m.conv1 = nn.Conv2d(in_ch, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        if in_ch == 1:\n",
    "            with torch.no_grad():\n",
    "                m.conv1.weight.copy_(w.sum(dim=1, keepdim=True))\n",
    "    in_dim = m.fc.in_features\n",
    "    m.fc = nn.Linear(in_dim, n_classes)\n",
    "    return m\n",
    "\n",
    "def compute_metrics(y_true, y_prob, n_classes: int):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_prob = np.asarray(y_prob)\n",
    "    y_pred = np.argmax(y_prob, axis=1)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    if n_classes == 2:\n",
    "        try:\n",
    "            auroc = roc_auc_score(y_true, y_prob[:, 1])\n",
    "        except Exception:\n",
    "            auroc = float('nan')\n",
    "    else:\n",
    "        y_true_1hot = np.eye(n_classes)[y_true]\n",
    "        try:\n",
    "            auroc = roc_auc_score(y_true_1hot, y_prob, average='macro', multi_class='ovr')\n",
    "        except Exception:\n",
    "            auroc = float('nan')\n",
    "    return {'acc': float(acc), 'auroc': float(auroc)}\n",
    "\n",
    "print('✅ Week 2 helpers ready.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8b6464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def train_one_model(model_name: str,\n",
    "                    finetune: str = 'head',\n",
    "                    epochs: int = 5,\n",
    "                    lr: float = 3e-4,\n",
    "                    weight_decay: float = 1e-4,\n",
    "                    batch_size: int = 128,\n",
    "                    label_frac: float = 1.0,\n",
    "                    device: str = None):\n",
    "    if device is None:\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"\\n=== Training {model_name} (finetune={finetune}) on {DATASET_KEY} ===\")\n",
    "    print(\"Using device:\", device)\n",
    "\n",
    "    train_loader, val_loader, test_loader, n_classes = get_loaders(\n",
    "        DATASET_KEY, batch_size=batch_size, label_frac=label_frac, seed=42\n",
    "    )\n",
    "\n",
    "    if model_name == 'smallcnn':\n",
    "        model = SmallCNN(in_ch=3, n_classes=n_classes)\n",
    "        params = model.parameters()\n",
    "    elif model_name == 'resnet18':\n",
    "        model = make_resnet18(n_classes=n_classes, in_ch=3, pretrained=True)\n",
    "        if finetune == 'head':\n",
    "            for p in model.parameters():\n",
    "                p.requires_grad = False\n",
    "            for p in model.fc.parameters():\n",
    "                p.requires_grad = True\n",
    "            params = model.fc.parameters()\n",
    "        else:\n",
    "            params = model.parameters()\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model_name: {model_name}\")\n",
    "\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(params, lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "\n",
    "    best_state = None\n",
    "    best_score = -1.0\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        loss_sum, n_sum = 0.0, 0\n",
    "        for x, y in train_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.squeeze().long().to(device)\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_sum += float(loss.item()) * x.size(0)\n",
    "            n_sum += x.size(0)\n",
    "\n",
    "        # validation\n",
    "        model.eval()\n",
    "        all_logits, all_y = [], []\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x = x.to(device)\n",
    "                logits = model(x)\n",
    "                all_logits.append(logits.cpu())\n",
    "                all_y.append(y)\n",
    "        all_logits = torch.cat(all_logits, dim=0)\n",
    "        all_y = torch.cat(all_y, dim=0).squeeze().numpy()\n",
    "        probs_val = torch.softmax(all_logits, dim=1).numpy()\n",
    "        metrics_val = compute_metrics(all_y, probs_val, n_classes=n_classes)\n",
    "        val_loss = loss_sum / max(1, n_sum)\n",
    "        score = metrics_val['auroc'] if not math.isnan(metrics_val['auroc']) else metrics_val['acc']\n",
    "        print(f\"[{model_name}][epoch {epoch:02d}] loss={val_loss:.4f} \"\n",
    "              f\"val_acc={metrics_val['acc']:.4f} val_auroc={metrics_val['auroc']:.4f}\")\n",
    "        scheduler.step()\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_state = model.state_dict()\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    # test evaluation\n",
    "    model.eval()\n",
    "    all_logits, all_y, all_imgs = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            all_imgs.append(x.cpu())\n",
    "            x = x.to(device)\n",
    "            logits = model(x)\n",
    "            all_logits.append(logits.cpu())\n",
    "            all_y.append(y)\n",
    "    all_logits = torch.cat(all_logits, dim=0)\n",
    "    all_y = torch.cat(all_y, dim=0).squeeze().numpy()\n",
    "    test_imgs = torch.cat(all_imgs, dim=0)\n",
    "    probs_test = torch.softmax(all_logits, dim=1).numpy()\n",
    "    metrics_test = compute_metrics(all_y, probs_test, n_classes=n_classes)\n",
    "    print(f\"[{model_name}] TEST acc={metrics_test['acc']:.4f} auroc={metrics_test['auroc']:.4f}\")\n",
    "\n",
    "    return model, metrics_test, all_y, probs_test, test_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394b0542",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 128\n",
    "LR = 3e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "\n",
    "results_dir = 'results_week2_example'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "smallcnn_model, metrics_small, y_test_small, p_test_small, imgs_test_small = train_one_model(\n",
    "    model_name='smallcnn',\n",
    "    finetune='head',\n",
    "    epochs=EPOCHS,\n",
    "    lr=LR,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "resnet_model, metrics_resnet, y_test_resnet, p_test_resnet, imgs_test_resnet = train_one_model(\n",
    "    model_name='resnet18',\n",
    "    finetune='head',\n",
    "    epochs=EPOCHS,\n",
    "    lr=LR,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "with open(os.path.join(results_dir, 'metrics_smallcnn.json'), 'w') as f:\n",
    "    json.dump(metrics_small, f, indent=2)\n",
    "with open(os.path.join(results_dir, 'metrics_resnet18_head.json'), 'w') as f:\n",
    "    json.dump(metrics_resnet, f, indent=2)\n",
    "\n",
    "print('Saved metrics JSON files to:', results_dir)\n",
    "print('smallcnn metrics:', metrics_small)\n",
    "print('resnet18-head metrics:', metrics_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55db5a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def reliability_diagram_with_ece(y_true, y_prob, n_bins: int = 10, strategy: str = 'equal_width', title_prefix: str = ''):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_prob = np.asarray(y_prob)\n",
    "    confidences = y_prob.max(axis=1)\n",
    "    preds = y_prob.argmax(axis=1)\n",
    "    correct = (preds == y_true).astype(float)\n",
    "\n",
    "    if strategy == 'equal_freq':\n",
    "        quantiles = np.linspace(0.0, 1.0, n_bins + 1)\n",
    "        bins = np.quantile(confidences, quantiles)\n",
    "        bins[0], bins[-1] = 0.0, 1.0  # ensure full coverage\n",
    "    else:  # 'equal_width'\n",
    "        bins = np.linspace(0.0, 1.0, n_bins + 1)\n",
    "\n",
    "    xs, bin_accs, bin_confs, bin_counts = [], [], [], []\n",
    "    ece = 0.0\n",
    "    n = len(confidences)\n",
    "\n",
    "    for i in range(n_bins):\n",
    "        lo, hi = bins[i], bins[i + 1]\n",
    "        if i == 0:\n",
    "            mask = (confidences >= lo) & (confidences <= hi)\n",
    "        else:\n",
    "            mask = (confidences > lo) & (confidences <= hi)\n",
    "        count = mask.sum()\n",
    "        center = (lo + hi) / 2.0\n",
    "        xs.append(center)\n",
    "        if count == 0:\n",
    "            bin_accs.append(0.0)\n",
    "            bin_confs.append(center)\n",
    "            bin_counts.append(0)\n",
    "            continue\n",
    "        acc_i = correct[mask].mean()\n",
    "        conf_i = confidences[mask].mean()\n",
    "        frac_i = count / max(1, n)\n",
    "        ece += abs(acc_i - conf_i) * frac_i\n",
    "        bin_accs.append(acc_i)\n",
    "        bin_confs.append(conf_i)\n",
    "        bin_counts.append(count)\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.plot([0, 1], [0, 1], linestyle='--')\n",
    "    width = 1.0 / n_bins\n",
    "    ax1.bar(xs, bin_accs, width=width, alpha=0.6, edgecolor='k')\n",
    "    ax1.plot(xs, bin_confs, marker='o')\n",
    "    ax1.set_xlabel('Confidence')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "\n",
    "    # Show fraction of samples as a second y-axis (simple histogram)\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.bar(xs, np.array(bin_counts) / max(1, n), width=width, alpha=0.3)\n",
    "    ax2.set_ylabel('Fraction of samples')\n",
    "\n",
    "    title = f\"{title_prefix} Reliability (ECE={ece:.3f}, {strategy})\"\n",
    "    ax1.set_title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return float(ece)\n",
    "\n",
    "# Example: ResNet18-head calibration snapshot\n",
    "ece_resnet_width = reliability_diagram_with_ece(\n",
    "    y_test_resnet,\n",
    "    p_test_resnet,\n",
    "    n_bins=15,\n",
    "    strategy='equal_width',\n",
    "    title_prefix='ResNet18-head'\n",
    ")\n",
    "ece_resnet_freq = reliability_diagram_with_ece(\n",
    "    y_test_resnet,\n",
    "    p_test_resnet,\n",
    "    n_bins=15,\n",
    "    strategy='equal_freq',\n",
    "    title_prefix='ResNet18-head'\n",
    ")\n",
    "\n",
    "print('ECE (equal-width bins):', ece_resnet_width)\n",
    "print('ECE (equal-frequency bins):', ece_resnet_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b1f7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Temperature Scaling (TS) for ResNet18-head\n",
    "# This is not required for Week 2, but many PneumoniaMNIST runs\n",
    "# see a noticeable ECE drop after a single TS step.\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "def collect_logits_and_labels(model, loader, device):\n",
    "    model.eval()\n",
    "    all_logits, all_y = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            logits = model(x)\n",
    "            all_logits.append(logits.cpu())\n",
    "            all_y.append(y)\n",
    "    all_logits = torch.cat(all_logits, dim=0)\n",
    "    all_y = torch.cat(all_y, dim=0).squeeze()\n",
    "    return all_logits, all_y\n",
    "\n",
    "_, val_loader, test_loader, _ = get_loaders(DATASET_KEY, batch_size=BATCH_SIZE, label_frac=1.0, seed=42)\n",
    "val_logits, val_y = collect_logits_and_labels(resnet_model, val_loader, device)\n",
    "test_logits, test_y = collect_logits_and_labels(resnet_model, test_loader, device)\n",
    "\n",
    "def tune_temperature(logits, labels, lr: float = 0.01, max_epochs: int = 100):\n",
    "    # Optimize log_T to keep T positive\n",
    "    log_T = torch.zeros(1, requires_grad=True)\n",
    "    optimizer = torch.optim.Adam([log_T], lr=lr)\n",
    "    nll = nn.CrossEntropyLoss()\n",
    "    for _ in range(max_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        loss = nll(logits / torch.exp(log_T), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return torch.exp(log_T).detach()\n",
    "\n",
    "T_opt = tune_temperature(val_logits, val_y)\n",
    "print('Optimal temperature T:', T_opt.item())\n",
    "\n",
    "p_test_TS = torch.softmax(test_logits / T_opt, dim=1).numpy()\n",
    "ece_resnet_TS = reliability_diagram_with_ece(\n",
    "    test_y.numpy(),\n",
    "    p_test_TS,\n",
    "    n_bins=15,\n",
    "    strategy='equal_width',\n",
    "    title_prefix='ResNet18-head + TS'\n",
    ")\n",
    "print('ECE after TS (equal-width bins):', ece_resnet_TS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d24468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Misclassified examples for ResNet18-head\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_misclassified_gallery(images, y_true, y_prob, n_examples: int = 5):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_prob = np.asarray(y_prob)\n",
    "    preds = y_prob.argmax(axis=1)\n",
    "    confidences = y_prob.max(axis=1)\n",
    "    wrong = np.where(preds != y_true)[0]\n",
    "    if len(wrong) == 0:\n",
    "        print('No misclassified examples found.')\n",
    "        return\n",
    "    order = np.argsort(-confidences[wrong])\n",
    "    sel = wrong[order][:n_examples]\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(sel), figsize=(3 * len(sel), 3))\n",
    "    if len(sel) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, idx in zip(axes, sel):\n",
    "        img = images[idx]\n",
    "        # images is a tensor of shape (N, C, H, W)\n",
    "        if hasattr(img, 'numpy'):\n",
    "            img_np = img.numpy()\n",
    "        else:\n",
    "            img_np = np.array(img)\n",
    "        if img_np.ndim == 3 and img_np.shape[0] in (1, 3):\n",
    "            img_np = np.transpose(img_np, (1, 2, 0))\n",
    "            if img_np.shape[2] == 1:\n",
    "                ax.imshow(img_np[:, :, 0], cmap='gray')\n",
    "            else:\n",
    "                ax.imshow(img_np)\n",
    "        else:\n",
    "            ax.imshow(img_np.squeeze(), cmap='gray')\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f'true={int(y_true[idx])}, pred={int(preds[idx])}\\nconf={confidences[idx]:.2f}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_misclassified_gallery(imgs_test_resnet, y_test_resnet, p_test_resnet, n_examples=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
